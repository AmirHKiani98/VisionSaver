{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7dcb3afb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Django 5.2.4 configured with processor.settings\n"
     ]
    }
   ],
   "source": [
    "# Cell 0: bootstrap Django using settings at ../processor/settings.py\n",
    "from pathlib import Path\n",
    "import sys, os\n",
    "\n",
    "# Ensure the parent directory (which contains the `processor` package) is on sys.path\n",
    "proj_parent = Path('..').resolve()\n",
    "if str(proj_parent) not in sys.path:\n",
    "    sys.path.insert(0, str(proj_parent))\n",
    "\n",
    "# Point Django to the settings module\n",
    "os.environ.setdefault('DJANGO_SETTINGS_MODULE', 'processor.settings')\n",
    "\n",
    "# Import and initialize Django\n",
    "try:\n",
    "    import django\n",
    "except ImportError as e:\n",
    "    raise ImportError(\"Django is not installed. Install it with: pip install django\") from e\n",
    "\n",
    "django.setup()\n",
    "\n",
    "# Optional: verify setup\n",
    "print(\"Django\", django.get_version(), \"configured with\", os.environ['DJANGO_SETTINGS_MODULE'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36e29781",
   "metadata": {},
   "source": [
    "My Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "74ca5050",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Record found: id=252, name=\n",
      "start_time=2025-11-04 08:57:54.230000-06:00, end_time=2025-11-04 11:57:54.230000-06:00, direction=West Bound\n",
      "Record found: id=253, name=\n",
      "start_time=2025-11-04 08:57:54.242000-06:00, end_time=2025-11-04 11:57:54.242000-06:00, direction=East Bound\n",
      "Record found: id=256, name=\n",
      "start_time=2025-11-04 11:58:25.734000-06:00, end_time=2025-11-04 17:58:25.734000-06:00, direction=East Bound\n",
      "Record found: id=257, name=\n",
      "start_time=2025-11-04 11:58:25.745000-06:00, end_time=2025-11-04 17:58:25.745000-06:00, direction=West Bound\n",
      "Record found: id=260, name=\n",
      "start_time=2025-11-04 06:00:38.447000-06:00, end_time=2025-11-04 07:00:38.447000-06:00, direction=East Bound\n",
      "Record found: id=261, name=\n",
      "start_time=2025-11-04 06:00:38.461000-06:00, end_time=2025-11-04 07:00:38.461000-06:00, direction=North Bound\n",
      "Record found: id=262, name=\n",
      "start_time=2025-11-04 06:00:38.473000-06:00, end_time=2025-11-04 07:00:38.473000-06:00, direction=West Bound\n"
     ]
    }
   ],
   "source": [
    "from ai.models import DetectionProcess\n",
    "from record.models import Record\n",
    "from api.utils import get_counter_auto_detection_results\n",
    "from asgiref.sync import sync_to_async\n",
    "from datetime import datetime, timedelta\n",
    "from zoneinfo import ZoneInfo\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "records = [\"252\", \"253\", \"256\", \"257\", \"260\", \"261\", \"262\"]\n",
    "\n",
    "for record_id in records:\n",
    "    # --- Retrieve record and metadata ---\n",
    "    try:\n",
    "        record = await sync_to_async(Record.objects.get)(id=record_id)\n",
    "    except Record.DoesNotExist:\n",
    "        record = None\n",
    "        print(f\"No Record found with id={record_id}\")\n",
    "\n",
    "    if record:\n",
    "        print(f\"Record found: id={record.id}, name={getattr(record, 'name', '')}\")\n",
    "\n",
    "        start_time = getattr(record, \"start_time\", None)\n",
    "        duration = getattr(record, \"duration\", None)\n",
    "        direction = getattr(record, \"direction\", None)\n",
    "        ip = getattr(record, \"camera_url\", None)\n",
    "        if \"192.168.30.44\" in ip:\n",
    "            intersection_name = \"Maple Grove\"\n",
    "        if \"192.168.30.76\" in ip:\n",
    "            intersection_name = \"Fernbrook\"\n",
    "        # Normalize direction\n",
    "        direction_map = {\n",
    "            \"east\": \"East Bound\",\n",
    "            \"west\": \"West Bound\",\n",
    "            \"north\": \"North Bound\",\n",
    "            \"south\": \"South Bound\",\n",
    "        }\n",
    "        direction = direction_map.get(direction, \"Unknown\")\n",
    "\n",
    "        # Compute end time\n",
    "        end_time = None\n",
    "        try:\n",
    "            if start_time and duration is not None:\n",
    "                if isinstance(duration, timedelta):\n",
    "                    mins = duration.total_seconds() / 60\n",
    "                else:\n",
    "                    mins = float(duration)\n",
    "                end_time = start_time + timedelta(minutes=mins)\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "        # Ensure timezone (America/Chicago)\n",
    "        CHI = ZoneInfo(\"America/Chicago\")\n",
    "\n",
    "        def to_chicago(dt):\n",
    "            if dt is None:\n",
    "                return None\n",
    "            if dt.tzinfo is None:\n",
    "                dt = dt.replace(tzinfo=ZoneInfo(\"UTC\"))\n",
    "            return dt.astimezone(CHI)\n",
    "\n",
    "        start_time = to_chicago(start_time)\n",
    "        end_time = to_chicago(end_time)\n",
    "\n",
    "        print(f\"start_time={start_time}, end_time={end_time}, direction={direction}\")\n",
    "\n",
    "    # --- Get detection process ---\n",
    "    try:\n",
    "        detection_process = await sync_to_async(DetectionProcess.objects.get)(\n",
    "            record_id=record_id, done=True\n",
    "        )\n",
    "    except DetectionProcess.DoesNotExist:\n",
    "        detection_process = None\n",
    "        print(f\"No DetectionProcess found for record_id={record_id}\")\n",
    "\n",
    "    # --- Process results ---\n",
    "    if detection_process:\n",
    "        results = await sync_to_async(get_counter_auto_detection_results)(\n",
    "            record_id, detection_process.version, detection_process.divide_time\n",
    "        )\n",
    "\n",
    "        cls_map = {2: \"car\", 3: \"motorcycle\", 5: \"bus\", 7: \"truck\"}\n",
    "        data = results[0]\n",
    "\n",
    "        records = []\n",
    "        for movement, records_dict in data.items():\n",
    "            for sec, vals in records_dict.items():\n",
    "                try:\n",
    "                    count, ids, cls_list = vals\n",
    "                except Exception:\n",
    "                    continue\n",
    "                cls_num = cls_list[0] if cls_list else None\n",
    "                cls_label = cls_map.get(cls_num, \"other\")\n",
    "                timestamp = start_time + timedelta(seconds=float(sec))\n",
    "                records.append(\n",
    "                    {\n",
    "                        \"movement\": movement,\n",
    "                        \"timestamp\": timestamp,\n",
    "                        \"count\": int(count),\n",
    "                        \"cls\": cls_label,\n",
    "                    }\n",
    "                )\n",
    "\n",
    "        df = pd.DataFrame(records)\n",
    "        if df.empty:\n",
    "            print(\"⚠️ No records found.\")\n",
    "        else:\n",
    "            # --- Filter between 6 AM and 6 PM ---\n",
    "            mask = (df[\"timestamp\"].dt.time >= datetime.strptime(\"06:00\", \"%H:%M\").time()) & \\\n",
    "                (df[\"timestamp\"].dt.time <= datetime.strptime(\"18:00\", \"%H:%M\").time())\n",
    "            df = df.loc[mask].copy()\n",
    "\n",
    "            # --- 15-minute bins ---\n",
    "            df[\"time_bin\"] = df[\"timestamp\"].dt.floor(\"15min\")\n",
    "\n",
    "            # --- STEP 1: total number of vehicles in each 15-min bin per movement ---\n",
    "            bin_summary = (\n",
    "                df.groupby([\"time_bin\", \"movement\"])[\"count\"]\n",
    "                .sum()\n",
    "                .unstack(fill_value=0)\n",
    "                .sort_index()\n",
    "            )\n",
    "\n",
    "            # --- STEP 2: totals of cars and trucks across all time per movement ---\n",
    "            car_totals = (\n",
    "                df.loc[df[\"cls\"] == \"car\"]\n",
    "                .groupby(\"movement\")[\"count\"]\n",
    "                .sum()\n",
    "                .reindex(bin_summary.columns, fill_value=0)\n",
    "            )\n",
    "            truck_totals = (\n",
    "                df.loc[df[\"cls\"] == \"truck\"]\n",
    "                .groupby(\"movement\")[\"count\"]\n",
    "                .sum()\n",
    "                .reindex(bin_summary.columns, fill_value=0)\n",
    "            )\n",
    "\n",
    "            # --- STEP 3: append car/truck totals as extra rows ---\n",
    "            final_summary = pd.concat(\n",
    "                [bin_summary,\n",
    "                pd.DataFrame([car_totals, truck_totals], index=[\"car\", \"truck\"])],\n",
    "                sort=False\n",
    "            )\n",
    "\n",
    "            # --- STEP 4: wrap columns under top-level header = direction ---\n",
    "            final_summary.columns = pd.MultiIndex.from_product([[direction], final_summary.columns])\n",
    "\n",
    "            # Ensure index datetimes are timezone-unaware for Excel (Excel does not support tz-aware datetimes).\n",
    "            # The index may contain mixed types (datetimes plus row labels like \"car\"/\"truck\"),\n",
    "            # so convert only Timestamp entries and leave others unchanged.\n",
    "            new_index = []\n",
    "            for v in final_summary.index:\n",
    "                if isinstance(v, pd.Timestamp):\n",
    "                    if v.tzinfo is not None:\n",
    "                        # remove tzinfo while preserving the wall-clock time\n",
    "                        new_index.append(v.to_pydatetime().replace(tzinfo=None))\n",
    "                    else:\n",
    "                        new_index.append(v.to_pydatetime())\n",
    "                else:\n",
    "                    new_index.append(v)\n",
    "            try:\n",
    "                final_summary.index = pd.Index(new_index)\n",
    "            except Exception:\n",
    "                # fallback: convert everything to string if assigning the new index fails\n",
    "                final_summary.index = pd.Index([str(x) for x in new_index])\n",
    "\n",
    "            # --- STEP 5: save to Excel ---\n",
    "            # build a safe filename: <intersection_name>_<direction>_<start>-<end>.xlsx\n",
    "            def _safe(s):\n",
    "                return \"\".join(c if c.isalnum() or c in (\"_\", \"-\") else \"_\" for c in str(s)).strip().replace(\"__\", \"_\")\n",
    "\n",
    "            if start_time and end_time:\n",
    "                # ensure times are in Chicago and use filesystem-safe format\n",
    "                st = start_time.astimezone(CHI) if getattr(start_time, \"tzinfo\", None) else start_time\n",
    "                et = end_time.astimezone(CHI) if getattr(end_time, \"tzinfo\", None) else end_time\n",
    "                st_str = st.strftime(\"%Y%m%d_%H_%M\")\n",
    "                et_str = et.strftime(\"%Y%m%d_%H_%M\")\n",
    "                base = f\"{intersection_name or record_id}_{direction or ''}_{st_str}-{et_str}\"\n",
    "            else:\n",
    "                base = f\"{intersection_name or record_id}_{direction or ''}\"\n",
    "\n",
    "            base = _safe(base)\n",
    "            output_file = (f\"{base}.xlsx\") if 'proj_parent' in globals() else Path(f\"{base}.xlsx\")\n",
    "            final_summary.to_excel(output_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f501d55",
   "metadata": {},
   "source": [
    "ISS Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b11f9019",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved results to Fernbrook_East_Bound_20251104_06_00-20251104_18_00.xlsx\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime, timedelta\n",
    "import requests\n",
    "from datetime import datetime\n",
    "from zoneinfo import ZoneInfo\n",
    "CHI = ZoneInfo(\"America/Chicago\")\n",
    "maple_grove_ip = \"192.168.30.44\"\n",
    "fernbrooke_ip = \"192.168.30.76\"\n",
    "is_maple_grove = False\n",
    "camera_id = 3\n",
    "# create UTC zoneinfo from the existing CHI object and convert parsed CHI times to UTC\n",
    "UTZ = CHI.__class__(\"UTC\")\n",
    "start_time = datetime.strptime(\"2025-11-04 06:00:00AM\", \"%Y-%m-%d %I:%M:%S%p\").replace(tzinfo=CHI).astimezone(UTZ)\n",
    "end_time = datetime.strptime(\"2025-11-04 06:00:00PM\", \"%Y-%m-%d %I:%M:%S%p\").replace(tzinfo=CHI).astimezone(UTZ)\n",
    "\n",
    "\n",
    "if is_maple_grove:\n",
    "    ip = maple_grove_ip\n",
    "else:\n",
    "    ip = fernbrooke_ip\n",
    "\n",
    "if is_maple_grove:\n",
    "    if camera_id == 1:\n",
    "        direction = \"East Bound\"\n",
    "    elif camera_id == 2:\n",
    "        direction = \"South Bound\"\n",
    "    elif camera_id == 3:\n",
    "        direction = \"West Bound\"\n",
    "    elif camera_id == 4:\n",
    "        direction = \"North Bound\"\n",
    "else:\n",
    "    if camera_id == 1:\n",
    "        direction = \"North Bound\"\n",
    "    elif camera_id == 2:\n",
    "        direction = \"West Bound\"\n",
    "    elif camera_id == 3:\n",
    "        direction = \"East Bound\"\n",
    "\n",
    "url = f\"http://{ip}/api/v1/cameras/{camera_id}/bin-statistics\"\n",
    "params = {\n",
    "    \"start-time\": start_time.strftime(\"%Y-%m-%dT%H:%M:%S\"),\n",
    "    \"end-time\": end_time.strftime(\"%Y-%m-%dT%H:%M:%S\")\n",
    "}\n",
    "try:\n",
    "    response = requests.get(url, params=params)\n",
    "    response.raise_for_status() \n",
    "    data = response.json()\n",
    "except requests.RequestException as e:\n",
    "    print(f\"Error fetching bin-statistics: {e}\")\n",
    "    None\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "# Process ISS data into similar format as detection results\n",
    "def process_iss_data(data, direction, start_time):\n",
    "    if not data or 'statistics' not in data:\n",
    "        print(\"⚠️ No statistics found in data\")\n",
    "        return None\n",
    "\n",
    "    # Create records list from statistics\n",
    "    records = []\n",
    "    for stat in data['statistics']:\n",
    "        # Convert UTC time to timestamp\n",
    "        timestamp = datetime.fromisoformat(stat['time'].replace('Z', '+00:00'))\n",
    "        timestamp = timestamp.astimezone(CHI)  # Convert to Chicago time\n",
    "        \n",
    "        # Map movements based on counts\n",
    "        movements = {\n",
    "            'through': stat.get('throughCount', 0),\n",
    "            'left_turn': stat.get('leftTurnCount', 0),\n",
    "            'right_turn': stat.get('rightTurnCount', 0)\n",
    "        }\n",
    "        \n",
    "        # Create a record for each movement type that has counts\n",
    "        for movement, count in movements.items():\n",
    "            if count > 0:\n",
    "                records.append({\n",
    "                    'movement': movement,\n",
    "                    'timestamp': timestamp,\n",
    "                    'count': count,\n",
    "                    'cls': 'vehicle'  # ISS doesn't provide vehicle classification\n",
    "                })\n",
    "\n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame(records)\n",
    "    if df.empty:\n",
    "        print(\"⚠️ No records found in statistics\")\n",
    "        return None\n",
    "\n",
    "    # --- Filter between 6 AM and 6 PM ---\n",
    "    mask = (df['timestamp'].dt.time >= datetime.strptime('06:00', '%H:%M').time()) & \\\n",
    "           (df['timestamp'].dt.time <= datetime.strptime('18:00', '%H:%M').time())\n",
    "    df = df.loc[mask].copy()\n",
    "\n",
    "    # --- 15-minute bins ---\n",
    "    df['time_bin'] = df['timestamp'].dt.floor('15min')\n",
    "\n",
    "    # --- STEP 1: total vehicles in each 15-min bin per movement ---\n",
    "    bin_summary = (\n",
    "        df.groupby(['time_bin', 'movement'])['count']\n",
    "        .sum()\n",
    "        .unstack(fill_value=0)\n",
    "        .sort_index()\n",
    "    )\n",
    "\n",
    "    # --- STEP 2: total counts (no car/truck split available in ISS data) ---\n",
    "    total_counts = df.groupby('movement')['count'].sum().reindex(bin_summary.columns, fill_value=0)\n",
    "\n",
    "    # --- STEP 3: append totals as extra row ---\n",
    "    final_summary = pd.concat(\n",
    "        [bin_summary,\n",
    "         pd.DataFrame([total_counts], index=['total'])],\n",
    "        sort=False\n",
    "    )\n",
    "\n",
    "    # --- STEP 4: wrap columns under top-level header = direction ---\n",
    "    final_summary.columns = pd.MultiIndex.from_product([[direction], final_summary.columns])\n",
    "\n",
    "    # Convert timezone-aware timestamps to naive for Excel compatibility\n",
    "    new_index = []\n",
    "    for v in final_summary.index:\n",
    "        if isinstance(v, pd.Timestamp):\n",
    "            if v.tzinfo is not None:\n",
    "                new_index.append(v.to_pydatetime().replace(tzinfo=None))\n",
    "            else:\n",
    "                new_index.append(v.to_pydatetime())\n",
    "        else:\n",
    "            new_index.append(v)\n",
    "    \n",
    "    try:\n",
    "        final_summary.index = pd.Index(new_index)\n",
    "    except Exception:\n",
    "        final_summary.index = pd.Index([str(x) for x in new_index])\n",
    "\n",
    "    return final_summary\n",
    "\n",
    "# Process and save the data\n",
    "if data:\n",
    "    intersection_name = \"Maple Grove\" if is_maple_grove else \"Fernbrook\"\n",
    "    final_summary = process_iss_data(data, direction, start_time)\n",
    "    \n",
    "    if final_summary is not None:\n",
    "        # Save to Excel with formatted filename\n",
    "        def _safe(s):\n",
    "            return \"\".join(c if c.isalnum() or c in (\"_\", \"-\") else \"_\" for c in str(s)).strip().replace(\"__\", \"_\")\n",
    "        \n",
    "        st_str = start_time.astimezone(CHI).strftime(\"%Y%m%d_%H_%M\")\n",
    "        et_str = end_time.astimezone(CHI).strftime(\"%Y%m%d_%H_%M\")\n",
    "        base = f\"{intersection_name}_{direction}_{st_str}-{et_str}\"\n",
    "        base = _safe(base)\n",
    "        output_file = Path(f\"{base}.xlsx\")\n",
    "        final_summary.to_excel(output_file)\n",
    "        print(f\"Saved results to {output_file}\")\n",
    "    else:\n",
    "        print(\"⚠️ Could not create summary from ISS data\")\n",
    "else:\n",
    "    print(\"⚠️ No data received from ISS API\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e97fe936",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved results to Maple_Grove_East_Bound_20251104_06_00-20251104_18_00.xlsx\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db045315",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.11.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
