{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fc1b237c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 3 cars, 3 traffic lights, 80.4ms\n",
      "Speed: 3.1ms preprocess, 80.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "model = YOLO('yolov8n.pt')  # Load a pre-trained YOLO model\n",
    "import cv2\n",
    "# from backend.ai.car_detection import CarDetection\n",
    "video_path = 'C:/Users/amki003/OneDrive - Hennepin County/Documents/Github/CameraVision/backend/media/503.mp4'\n",
    "model = YOLO('yolov8n.pt')  # Load a pre-trained YOLO model\n",
    "video_capture = cv2.VideoCapture(video_path)\n",
    "fps = video_capture.get(cv2.CAP_PROP_FPS)\n",
    "frame_number = 130 *fps \n",
    "image_from_video = video_capture.set(cv2.CAP_PROP_POS_FRAMES, frame_number)\n",
    "success, frame = video_capture.read()\n",
    "if not success:\n",
    "    raise Exception(\"Could not read frame from video\")\n",
    "    \n",
    "result = model.predict(frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "22f5a0b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "boxes = result[0].boxes.data\n",
    "classes = result[0].boxes.cls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "420d7f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "ooi = [\"car\", \"motorcycle\", \"bus\", \"truck\"]\n",
    "ids = [int(key) for key, value  in result[0].names.items() if value in ooi]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ba4ab727",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor([1119.8533,  616.6497, 1161.0396,  717.5420]) tensor(9.)\n",
      "1 tensor([1081.5831,  188.6537, 1157.5087,  238.2034]) tensor(2.)\n",
      "2 tensor([595.5149, 393.2700, 703.9785, 498.0474]) tensor(2.)\n",
      "3 tensor([1120.1842,   63.2618, 1149.9677,  127.4643]) tensor(9.)\n",
      "4 tensor([1048.0994,  380.9526, 1106.8279,  409.1573]) tensor(2.)\n",
      "5 tensor([281.3820, 176.3354, 307.5404, 225.6300]) tensor(9.)\n"
     ]
    }
   ],
   "source": [
    "for index, box in enumerate(result[0].boxes.xyxy):\n",
    "    print(index, box, classes[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c95261a5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
